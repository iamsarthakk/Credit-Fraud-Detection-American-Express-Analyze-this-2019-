{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "      <th>VAR8</th>\n",
       "      <th>VAR9</th>\n",
       "      <th>VAR10</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR12</th>\n",
       "      <th>VAR13</th>\n",
       "      <th>VAR14</th>\n",
       "      <th>VAR15</th>\n",
       "      <th>VAR16</th>\n",
       "      <th>VAR17</th>\n",
       "      <th>VAR18</th>\n",
       "      <th>VAR19</th>\n",
       "      <th>VAR20</th>\n",
       "      <th>VAR21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>828.235294</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>321.428571</td>\n",
       "      <td>625.911006</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.081550</td>\n",
       "      <td>198.113469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>100.083403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.540594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.104991</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>911.764706</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611.574748</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>1.344479</td>\n",
       "      <td>198.600020</td>\n",
       "      <td>22.086661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.012510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.614613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146.654045</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>962.352941</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>615.825381</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>0.720796</td>\n",
       "      <td>197.267767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>210.175146</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.044599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.249570</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>892.941177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>638.076431</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.820218</td>\n",
       "      <td>197.355744</td>\n",
       "      <td>4.363431</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.862306</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>914.117647</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>626.514988</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>1.372928</td>\n",
       "      <td>198.790477</td>\n",
       "      <td>85.938202</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>210.175146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.558341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.268503</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAR1        VAR2      VAR3        VAR4        VAR5      VAR6      VAR7  \\\n",
       "0     1  828.235294  0.138889  321.428571  625.911006  1.818182  1.081550   \n",
       "1     2  911.764706  0.027778         NaN  611.574748  8.181818  1.344479   \n",
       "2     3  962.352941  0.833333   35.714286  615.825381  8.181818  0.720796   \n",
       "3     4  892.941177       NaN         NaN  638.076431  9.090909  0.820218   \n",
       "4     5  914.117647  0.083333         NaN  626.514988  5.181818  1.372928   \n",
       "\n",
       "         VAR8       VAR9      VAR10   ...         VAR12  VAR13  VAR14 VAR15  \\\n",
       "0  198.113469        NaN  58.632548   ...    100.083403    1.0      1   1.0   \n",
       "1  198.600020  22.086661        NaN   ...     15.012510    NaN      1   NaN   \n",
       "2  197.267767        NaN  58.632548   ...    210.175146   10.0      1  10.0   \n",
       "3  197.355744   4.363431  58.632548   ...           NaN    NaN      1   NaN   \n",
       "4  198.790477  85.938202  58.632548   ...    210.175146    NaN      .   NaN   \n",
       "\n",
       "      VAR16  VAR17  VAR18  VAR19       VAR20   VAR21  \n",
       "0  1.540594    NaN      1      0  100.104991     Low  \n",
       "1  1.614613    NaN      0      1  146.654045    High  \n",
       "2  1.044599    NaN      0      0   98.249570  Medium  \n",
       "3  1.145729    NaN      1      0  140.862306     Low  \n",
       "4  1.558341    NaN      1      0  101.268503    High  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('development_dataset.csv')\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAR1         0\n",
       "VAR2       961\n",
       "VAR3      3385\n",
       "VAR4     12494\n",
       "VAR5         1\n",
       "VAR6      3495\n",
       "VAR7       835\n",
       "VAR8       835\n",
       "VAR9     15817\n",
       "VAR10     4550\n",
       "VAR11     7565\n",
       "VAR12    10502\n",
       "VAR13     8522\n",
       "VAR14        0\n",
       "VAR15     8024\n",
       "VAR16      866\n",
       "VAR17    22194\n",
       "VAR18        0\n",
       "VAR19        0\n",
       "VAR20        0\n",
       "VAR21        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hg = train[train['VAR21']==\"High\"]\n",
    "# lw = train[train['VAR21']==\"Low\"]\n",
    "# md = train[train['VAR21']==\"Medium\"]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hg = hg.fillna(value = hg.median(axis=0))\n",
    "# lw = lw.fillna(value = lw.median(axis=0))\n",
    "# md = md.fillna(value = md.median(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = train.VAR21\n",
    "train.drop(['VAR21','VAR1'], 1, inplace=True)\n",
    "# train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34000, 19)"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train1 = pd.concat([hg,lw,md],axis = 0)\n",
    "# train1.drop(['VAR21','VAR1'], 1, inplace=True)\n",
    "\n",
    "train1 = train.copy()\n",
    "# train1.drop(['VAR16'], 1, inplace=True)\n",
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1['VAR2'] = train['VAR2'].apply(lambda x:hg.median if np.isnan(train['VAR21']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1['VAR2'] = train['VAR2'].fillna(train['VAR2'].mean())\n",
    "train1['VAR3'] = train['VAR3'].fillna(train['VAR3'].mean())\n",
    "train1['VAR4'] = train['VAR4'].fillna(train['VAR4'].mean())\n",
    "train1['VAR5'] = train['VAR5'].fillna(train['VAR5'].mean())\n",
    "train1['VAR6'] = train['VAR6'].fillna(train['VAR6'].mean())\n",
    "train1['VAR7'] = train['VAR7'].fillna(train['VAR7'].mean())\n",
    "train1['VAR8'] = train['VAR8'].fillna(train['VAR8'].mean())\n",
    "train1['VAR9'] = train['VAR9'].fillna(train['VAR9'].mean())\n",
    "train1['VAR10'] = train['VAR10'].fillna(train['VAR10'].mean())\n",
    "train1['VAR11'] = train['VAR11'].fillna(train['VAR11'].mean())\n",
    "train1['VAR12'] = train['VAR12'].fillna(train['VAR12'].mean())\n",
    "train1['VAR13'] = train['VAR13'].fillna(train['VAR13'].mean())\n",
    "train1['VAR15'] = train['VAR15'].fillna(train['VAR15'].mean())\n",
    "train1['VAR16'] = train['VAR16'].fillna(train['VAR16'].mean())\n",
    "\n",
    "train1['VAR17'] = train['VAR2'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = targets.copy()\n",
    "j=0\n",
    "# target=[]\n",
    "for i in range(targets.shape[0]):\n",
    "    if targets[i] == 'High':\n",
    "        target[j] = 1\n",
    "    elif targets[i] == 'Medium':\n",
    "        target[j] = 0\n",
    "    elif targets[i] == 'Low':\n",
    "        target[j] = -1\n",
    "    j+=1\n",
    "# target=target.astype(â€˜intâ€™)  \n",
    "# target\n",
    "# targets.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.VAR14.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1[\"VAR14\"] = train1[\"VAR14\"].apply(lambda x: int(x) if x!=\".\" else 1)\n",
    "\n",
    "# for i in range(train1.VAR14.shape[0]):\n",
    "#     if train1.VAR14[i] == '.':\n",
    "#         train1.VAR14[i] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.VAR14.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27200, 19) (6800, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train1 = train1.toarray()\n",
    "X_train,X_test,y_train,y_test = train_test_split(train1.values,target.values,test_size=0.2)\n",
    "print(X_train.shape,X_test.shape)\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1.drop(['VAR21','VAR1'], 1, inplace=True)\n",
    "\n",
    "# import seaborn as sns\n",
    "# print(train1.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train,dtype=np.float64)\n",
    "y_test = np.asarray(y_test,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = np.asarray(train1.values,dtype=np.float64)\n",
    "target = np.asarray(target.values,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sarthak\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sarthak\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5511176470588235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train, target)\n",
    "predictions_LR = logisticRegr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_LR = confusion_matrix(target, predictions_LR)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions_LR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5597058823529412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sarthak\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_network = MLPClassifier(solver='adam', alpha=0.0001, hidden_layer_sizes=(7, 7), random_state=1)\n",
    "neural_network.fit(X_train, y_train)\n",
    "predictions_NN = neural_network.predict(X_test)\n",
    "\n",
    "#Confusion Matrix \n",
    "cm_NN = confusion_matrix(y_test, predictions_NN)\n",
    "print(accuracy_score(y_test, predictions_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5651470588235294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100,  criterion=\"gini\", max_depth=100, random_state=0)\n",
    "\n",
    "# rf.fit(train1,target)\n",
    "# predictions_RF = rf.predict(train1)\n",
    "\n",
    "# cm_RF = confusion_matrix(target, predictions_RF)\n",
    "# print(accuracy_score(target, predictions_RF))\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "predictions_RF = rf.predict(X_test)\n",
    "\n",
    "#Confusion Matrix \n",
    "cm_RF = confusion_matrix(y_test, predictions_RF)\n",
    "print(accuracy_score(y_test, predictions_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# multi_naive_bayes = MultinomialNB()\n",
    "# multi_naive_bayes.fit(X_train, y_train)\n",
    "# predictions_MNB = multi_naive_bayes.predict(X_test)\n",
    "\n",
    "# #Confusion Matrix \n",
    "# cm_MNB = confusion_matrix(y_test, predictions_MNB)\n",
    "# print(accuracy_score(y_test, predictions_MNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5438235294117647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(dual=False)\n",
    "svc.fit(X_train, y_train)\n",
    "predictions_SVC = svc.predict(X_test)\n",
    "\n",
    "#Confusion Matrix \n",
    "cm_SVC = confusion_matrix(y_test, predictions_SVC)\n",
    "print(accuracy_score(y_test, predictions_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(12, input_dim=19, activation='relu'))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='mse', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=4, batch_size=10)\n",
    "# _, accuracy = model.evaluate(X_test, y_test)\n",
    "# print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Embedding\n",
    "\n",
    "# model1=Sequential()\n",
    "# model1.add(Embedding(2000,100,mask_zero=True))\n",
    "# model1.add(LSTM(64,return_sequences=True))\n",
    "# model1.add(LSTM(32,return_sequences=False))\n",
    "# model1.add(Dense(1,activation='softmax'))\n",
    "# # model1.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "\n",
    "# # model = build_model()\n",
    "# model1.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"acc\"])\n",
    "# model1.fit(X_train, y_train, epochs=2, batch_size=100)\n",
    "# _, accuracy = model1.evaluate(X_test, y_test)\n",
    "# print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.31%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XG = XGBClassifier(\n",
    "                  max_depth = 4,\n",
    "                  min_child_weight = 2,\n",
    "                  gamma=0.2,\n",
    "                  subsample=1,\n",
    "                  colsample_bytree =0.6,\n",
    "                  learning_rate =0.1,\n",
    "                  n_estimators=100,\n",
    "                  objective= 'binary:logistic',\n",
    "                  nthread=6,\n",
    "                  scale_pos_weight=1)\n",
    "\n",
    "# XG.fit(train1, target)\n",
    "XG.fit(X_train, y_train)\n",
    "\n",
    "predictions = XG.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "#print(\"F1_score: {}\".format(f1_score(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"F1_score: {}\".format(f1_score(y_test,predictions,labels=[0,1,2],average=\"micro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "      <th>VAR8</th>\n",
       "      <th>VAR9</th>\n",
       "      <th>VAR10</th>\n",
       "      <th>VAR11</th>\n",
       "      <th>VAR12</th>\n",
       "      <th>VAR13</th>\n",
       "      <th>VAR14</th>\n",
       "      <th>VAR15</th>\n",
       "      <th>VAR16</th>\n",
       "      <th>VAR17</th>\n",
       "      <th>VAR18</th>\n",
       "      <th>VAR19</th>\n",
       "      <th>VAR20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>878.823529</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>821.428571</td>\n",
       "      <td>620.835806</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>0.833974</td>\n",
       "      <td>197.500187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>9.433609</td>\n",
       "      <td>40.033361</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.212784</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.099828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>891.764706</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>357.142857</td>\n",
       "      <td>614.092215</td>\n",
       "      <td>3.909091</td>\n",
       "      <td>0.595187</td>\n",
       "      <td>197.016843</td>\n",
       "      <td>253.896073</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>10.144612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>1.004907</td>\n",
       "      <td>992.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104.018933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>955.294118</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611.574748</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>0.918652</td>\n",
       "      <td>197.660051</td>\n",
       "      <td>22.086661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.157115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120.586919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>831.764706</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>617.740617</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>2.383924</td>\n",
       "      <td>200.526288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.539365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.350858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168.592083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>957.647059</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>623.426802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.711240</td>\n",
       "      <td>197.151458</td>\n",
       "      <td>5.013668</td>\n",
       "      <td>49.379748</td>\n",
       "      <td>0.255712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>1.171551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>109.204819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAR1        VAR2      VAR3        VAR4        VAR5      VAR6      VAR7  \\\n",
       "0     1  878.823529  0.833333  821.428571  620.835806  5.181818  0.833974   \n",
       "1     2  891.764706  0.138889  357.142857  614.092215  3.909091  0.595187   \n",
       "2     3  955.294118  0.055556         NaN  611.574748  6.363636  0.918652   \n",
       "3     4  831.764706  0.111111  250.000000  617.740617  6.545455  2.383924   \n",
       "4     5  957.647059  0.166667         NaN  623.426802       NaN  0.711240   \n",
       "\n",
       "         VAR8        VAR9      VAR10      VAR11      VAR12      VAR13 VAR14  \\\n",
       "0  197.500187         NaN  58.632548   9.433609  40.033361  10.000000     2   \n",
       "1  197.016843  253.896073  58.632548  10.144612        NaN   5.666667     1   \n",
       "2  197.660051   22.086661        NaN   0.583494        NaN   6.000000     1   \n",
       "3  200.526288         NaN  48.539365        NaN        NaN        NaN     3   \n",
       "4  197.151458    5.013668  49.379748   0.255712        NaN  13.333333     1   \n",
       "\n",
       "       VAR15     VAR16    VAR17  VAR18  VAR19       VAR20  \n",
       "0  10.000000  1.212784  1000.00      1      0   48.099828  \n",
       "1   7.600000  1.004907   992.55      0      0  104.018933  \n",
       "2   6.000000  1.157115      NaN      1      1  120.586919  \n",
       "3        NaN  2.350858      NaN      0      1  168.592083  \n",
       "4  13.333333  1.171551      NaN      0      1  109.204819  "
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv('leaderboard_dataset.csv')\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAR2      267\n",
       "VAR3      937\n",
       "VAR4     3686\n",
       "VAR5        0\n",
       "VAR6     1058\n",
       "VAR7      215\n",
       "VAR8      215\n",
       "VAR9     4701\n",
       "VAR10    1348\n",
       "VAR11    2231\n",
       "VAR12    3201\n",
       "VAR13    2493\n",
       "VAR14       0\n",
       "VAR15    2359\n",
       "VAR16     229\n",
       "VAR17    6543\n",
       "VAR18       0\n",
       "VAR19       0\n",
       "VAR20       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.drop(['VAR1'], 1, inplace=True)\n",
    "test1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1['VAR2'] = test1['VAR2'].fillna(train['VAR2'].median())\n",
    "test1['VAR3'] = test1['VAR3'].fillna(train['VAR3'].median())\n",
    "test1['VAR4'] = test1['VAR4'].fillna(train['VAR4'].median())\n",
    "# train1['VAR5'] = train['VAR5'].fillna(train['VAR5'].mean())\n",
    "test1['VAR6'] = test1['VAR6'].fillna(train['VAR6'].median())\n",
    "test1['VAR7'] = test1['VAR7'].fillna(train['VAR7'].median())\n",
    "test1['VAR8'] = test1['VAR8'].fillna(train['VAR8'].median())\n",
    "test1['VAR9'] = test1['VAR9'].fillna(train['VAR9'].median())\n",
    "test1['VAR10'] = test1['VAR10'].fillna(train['VAR10'].median())\n",
    "test1['VAR11'] = test1['VAR11'].fillna(train['VAR11'].median())\n",
    "test1['VAR12'] = test1['VAR12'].fillna(train['VAR12'].median())\n",
    "test1['VAR13'] = test1['VAR13'].fillna(train['VAR13'].median())\n",
    "test1['VAR15'] = test1['VAR15'].fillna(train['VAR15'].median())\n",
    "test1['VAR16'] = test1['VAR16'].fillna(train['VAR16'].median())\n",
    "\n",
    "test1['VAR17'] = test1['VAR2'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[\"VAR14\"] = test1[\"VAR14\"].apply(lambda x: int(x) if x!=\".\" else 1)\n",
    "\n",
    "# for i in range(test1.VAR14.shape[0]):\n",
    "#     if test1.VAR14[i] == '.':\n",
    "#         test1.VAR14[i] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.asarray(test1.values,dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. -1.  0. ...  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "predictions = XG.predict(test1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "count=1\n",
    "with io.open('Sting_IITKanpur_2.csv', 'w') as writeFile:\n",
    "    \n",
    "    for i in predictions:\n",
    "        if i==-1:\n",
    "            writeFile.write(str(count)+',Low,\\n')\n",
    "        elif i==0:\n",
    "            writeFile.write(str(count)+',Medium,\\n')\n",
    "        elif i==1:\n",
    "            writeFile.write(str(count)+',High,\\n')\n",
    "        count+=1\n",
    "\n",
    "            \n",
    "writeFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.53%\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
